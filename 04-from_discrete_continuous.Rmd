---
output:
    bookdown::html_document2: default
---
# From Discrete to Continuous Cases {#DiscreteContinuous}
```{r, discrete setup, include=FALSE}
library(tidyverse)
library(cowplot)
theme_set(theme_light())
set.seed(0)
```

## Normal Approximation and DeMoivre's Problem

In a way, the binomial distribution is the parent of the normal distribution. I'll explain.

Several centuries ago, mathematician Abraham DeMoivre was asked to solve a gambling problem requiring him to flip a coin many times and counts the total number of heads. After repeatedly playing the game, he found that his results resembled a unique bellcurve shape.

In this section, we will simulate his experiment:

- First, we will use R to create a coin. The heads side of our fair coin will be represented with a "H" and tails with a "T".

```{r, coin}
coin <- c("H","T")
```

- Next, we will use `sample` to simulate random coin flips. The first argument of the function is for the elements of our random sampling process. The second `size` is the number of times that we will flip the coin. Finally, we will set `replace` to `TRUE` so that we keep both sides of our coin after flipping. 

```{r, random-coins}
flips <- tibble(flip_num = 1:3600, 
                outcome = sample(coin, size = 3600, replace = TRUE))

head(flips, 5)
```

- Now, let's save the total number of heads.

```{r, save-heads}
heads <- flips %>% 
  filter(outcome == "H") %>% 
  count()

heads
```

- Our last step is to find a way to repeat this game of 3600 flips. We will do so by creating a function.

```{r, coin-function}
get_heads <- function() {
  fair_coin <- c("H", "T") # Repeating code from the previous lines.
  flip <- tibble(flip_num = 1:3600, 
                 outcome = sample(fair_coin, size = 3600, replace = TRUE))
  heads_count <- flip %>% filter(outcome == "H") %>% count()
  return(heads_count)
}
```

- Using this function, we will repeat the coin flip game 1000 times and count the number of heads using `replicate`. Read more about the function's documentation by typing `?replicate` into the console.

```{r, coin-game}
outcomes <- tibble(game_num = 1:1000,
                   heads = as.numeric(replicate(1000, get_heads(), simplify = TRUE))) 

head(outcomes, 5)
```

- What does this look like? We will first save a ggplot object called `demoivre_plot` and then make a histogram.
  
```{r, coinplot-hist, fig.cap= "Coin game simulation with geom_histogram", fig.align="center", out.width="60%"}
# Plotting our game outcomes

demoivre_plot <- ggplot(outcomes, aes(x = heads))
  
demoivre_plot +
  geom_histogram(bins = 25) +
  labs(x = "Heads", y = "Count")
```

You can start to see the bell shape taking form in Figure \@ref(fig:coinplot-hist). However, this is even easier to see with `geom_density()` which takes the same aesthetic mapping as `geom_histogram`.

```{r, coinplot-density, fig.cap= "Coin game simulation with geom_density", fig.align="center", out.width="60%"}
demoivre_plot +
  geom_density(alpha = 0.4, fill = "lightsteelblue") +
  labs(x = "Heads", y = "Density")
```

This unique bellcurve roughly follows the **normal distribution**. 

This distribution is useful beyond the coin flipping game. It is also resembles many everyday phenomena such as heights, IQ scores, salaries, and blood pressure. Because of this, when we know that an outcomes, people, or observations are independent and normally distributed, we can make *inferences* about the larger picture.

***

## Normal Distribution

Now let's return to the normal distribution. We can define it as follows:

$$f(x)=(2\pi)^{-1/2}e^{-x^2/2} \quad \textrm{for} \enspace -\infty < x < \infty$$

The fact that $x$ can take non-positive and non-integer values differentiates the normal distribution from [discrete distributions](#Discrete). These such distributions are considered **continuous**.

The density function `dnorm(x)` can be thought of as f(x). The first argument x contains a vector of numbers that will yield their density. Let's try this with $x = 1.5$ on a standard normal distribution. This means that the mean of the distribution is 0 and the standard deviation is 1. 

How likely is it that a point would be 1.5 standard deviations above the mean?

```{r, dnorm}
dnorm(1.5, mean = 0, sd = 1) #The mean and sd arguments are set to these values by default.
```

To interpret this density, simply think of 13% as the probability that an observation would be 1.5 standard deviations greater than a mean. 
  
There are many real world scenarios in which we could apply this. For instance, the probability of an American male having a height that is 1.5 standard deviations greater than average (i.e. 76 inches or 6 feet and 3 inches) is about 13%.

***

Oftentimes, we don't have a standardized distribution with 0 as the mean and 1 as the standard deviation. To demonstrate this, we'll return to our height example. The average height of men in the United States is 70 inches with 2 inches as the standard deviation. Thus, we must reevaluate the `mean` and `sd` arguments.

```{r, height-args}
normal <- list(mean = 70, sd = 2)
```

We can visualize this differently than discrete distributions. `stat_function` is a unique tool within ggplot that plots continuous curves. There are several required arguments:

1. a geometry such as "function", "point", "area," etc.,
2. a continuous function,
3. lower and upper limits on the x and/or x axis,
4. and a list of arguments for the function.

We listed our arguments for a normal curve above. After plotting this curve, we will add a vertical line at the mean using `geom_vline`. For this geometry, we are required to provide an x-intercept.

```{r, normal-plot, fig.cap= "Normal distribution of U.S. male heights", fig.align="center", out.width="60%"}
normal_plot <- ggplot() +
  stat_function(
    geom = "function",
    fun = dnorm,
    xlim = c(61, 79),
    args = normal # This is the list of arguments from above
  ) +
  geom_vline(xintercept = 70, color = "lightsteelblue", linetype = "dashed") +
  labs(x = "Height (inches)", y = "Density")

normal_plot
```

Unlike the geometric and binomial distributions, the normal distribution is symmetric about the mean. When a height is much greater or smaller than the average, it is less likely to occur.

***

Now that we have made our density plot, we can again capture an interval of values in the distribution with our "p" distribution function `pnorm()`. If the shortest Duke basketball player (in the 2020-21 season) is 6 feet or 72 inches tall, what percentage of the American male population is shorter than the basketball team?

```{r, round-pnorm}
round(pnorm(72, 70, 2), digits = 3) * 100 # Multiply by 100 to get a percentage
```

To understand what the lower 84.1% of the normal distribution looks like, we will create two geometries with `stat_function` in Figure \@ref(fig:pnorm-plot). The first will shade the entire distribution gray. On top of that, the second `stat_function` geometry fills the area of the distribution lower than 72 inches blue.

```{r, pnorm-plot, fig.cap= "U.S. male heights below 72 inches", fig.align="center", out.width="60%"}
ggplot() +
  stat_function(fun = dnorm, # Plot the entire distribution
                geom = "area",
                fill = "lightgray",
                color = "black",
                xlim = c(61, 79),
                args = normal) +
  stat_function(fun = dnorm, # Change the color of heights < 72 inches.
                geom = "area",
                fill = "steelblue",
                xlim = c(61, 72),
                args = normal
                ) +
  labs(x = "Height (inches)", y = "Density")
```

As the blue portion of the plot makes clear, a majority of American men have heights below 72 inches.

***

We use `rnorm` whenever we want to draw random samples from the normal distribution. On its own, the function helps us better understand the natural variation of real world processes that draw from normal distributions. If we repeat this sampling many times, we'll have a plot that more closely resembles the *true* distribution.

Let's apply this concept again to height. Imagine that you took a random sample of 50 US men and took their height.

```{r, sample-heights, fig.cap= "Heights of U.S. men, n = 50", fig.align="center", out.width="60%"}
# Take sample
sample_50 <- tibble(deviates = rnorm(50, 70, 2))

# Plot as a histogram
ggplot(sample_50, aes(x = deviates)) +
  geom_histogram(bins = 20)
```

If we took a larger sample, we would get something that looks more normally distributed.

```{r, large-sample, fig.cap= "Heights of U.S. men, n = 5000", fig.align="center", out.width="60%"}
sample_5000 <- tibble(deviates = rnorm(5000, 70, 2))

ggplot(sample_5000, aes(x = deviates)) +
  geom_histogram(bins = 20)
```

The plots below will more finely measure this progression as sample sizes increase:

```{r, samples-comp, fig.cap= "Comparison of samples to normal distribution", fig.align="center", out.width="60%"}
# Create a function that randomly samples from normal distribution
norm_plot <- function(mean, sd, n){
  temp <- tibble(deviates = rnorm(n, mean, sd))
  plot <- ggplot(temp, aes(x = deviates)) +
    geom_histogram(bins = 20)
  return(plot)
}

# Produce plots
sample_50 <- norm_plot(70, 2, 50)
sample_500 <- norm_plot(70, 2, 500)
sample_5000 <- norm_plot(70, 2, 5000)

# Plot together
cowplot::plot_grid(NULL, normal_plot, NULL, sample_50, sample_500, sample_5000, ncol = 3, nrow = 2)
```

Now that we have looked at the normal distribution, let's continue to look at other continuous random variables.
